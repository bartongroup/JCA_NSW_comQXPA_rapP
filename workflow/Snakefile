from pathlib import Path
import pandas as pd
from Bio import SeqIO
from json import load

from common import (
    get_taxa_name,
    combine_metadata
)

busco_lineage = 'bacillales_odb10'
busco_threshold = 98
gtdb_version = '226'

cwd = Path('.').resolve()

NCBI_TAXID = "1423"
SPECIES = "Bacillus subtilis" 

GENOME_FILES = Path('data/full/fasta/genomes').glob('*')
GENOMES = [genome.stem for genome in GENOME_FILES]
METADATA_FILE = list(Path('data/full/').glob('Bacillus_subtilis_complete_genomes*'))[0]

BAKTA_DB_FILES = [ 'antifam.h3f', 'antifam.h3i', 'antifam.h3m', 'antifam.h3p', 'bakta.db',
        'expert-protein-sequences.dmnd', 'ncRNA-genes.i1f', 'ncRNA-genes.i1i', 'ncRNA-genes.i1m',
        'ncRNA-genes.i1p', 'ncRNA-regions.i1f', 'ncRNA-regions.i1i', 'ncRNA-regions.i1m',
        'ncRNA-regions.i1p', 'oric.fna', 'orit.fna', 'pfam.h3f', 'pfam.h3i', 'pfam.h3m', 'pfam.h3p',
        'rfam-go.tsv', 'rRNA.i1f', 'rRNA.i1i', 'rRNA.i1m', 'rRNA.i1p', 'sorf.dmnd'
    ]
BAKTA_DB = expand('databases/bakta/db/{file}', file = BAKTA_DB_FILES)
BAKTA_SUFFIXES = ['tsv', 'gff3', 'gbff', 'embl', 'fna', 'ffn', 'faa', 
    'hypotheticals.tsv', 'hypotheticals.faa', 'json', 'txt', 'png', 'svg']
BAKTA_ANNOTS = expand('data/full/annotations/{genome}/{genome}.{suffix}', genome = GENOMES, suffix = BAKTA_SUFFIXES)

PROTEIN_FASTA = expand('data/full/fasta/proteins/{genome}.fasta', genome = GENOMES)
PROTEIN_BLAST_SUFFIXES = ['pdb','phr','pin','pjs','pot','psq','ptf','pto']
PROTEIN_BLAST_DB = expand('data/full/blast_db/proteins/{genome}.{suffix}', genome = GENOMES, suffix = PROTEIN_BLAST_SUFFIXES)

COM_PROTEINS = expand('data/full/fasta/com_proteins/{gene}.faa', gene=['comA','comP','comQ', 'comX'])

BUSCO_DATA = expand('databases/busco/lineages/{busco_lineage}/dataset.cfg', busco_lineage = busco_lineage)
BUSCOS = expand('data/full/busco/{genome}/run_{lineage}/full_table.tsv', genome = GENOMES, lineage = busco_lineage)

SKANI = ["results/skani/skani.out"]
SKANI_PLOT = ["results/skani/skani.pdf"]

# Way too many files in GTDB to list them all, so just one as a target
GTDB = ['databases/gtdbtk/taxonomy/gtdb_taxonomy.tsv']
GTDBTK = ['results/gtdbtk/gtdbtk.bac120.summary.tsv']

CLASSIFIED_METADATA = [str(METADATA_FILE).replace('complete_genomes','metadata')]

with open('data/full/id_mapping.json') as fh:
    json_map = load(fh)

strain_map = {}
for k,v in json_map.items():
    if v['strain'] is not None:
        strain_map[v['accession']] = v['strain']

rule all:
    input: PROTEIN_BLAST_DB + BUSCOS + SKANI_PLOT + COM_PROTEINS

rule bakta_db:
    output: BAKTA_DB
    singularity: "docker://quay.io/biocontainers/bakta:1.11.0--pyhdfd78af_0"
    log: 'workflow/logs/bakta_db.log'
    shell: 'bakta_db download --type full -o databases/bakta > {log} 2>&1'

rule bakta:
    input: 
        fasta = 'data/full/fasta/genomes/{genome}.fasta', 
        db = BAKTA_DB
    output: 'data/full/annotations/{genome}/{genome}.tsv', 'data/full/annotations/{genome}/{genome}.gff3', 'data/full/annotations/{genome}/{genome}.gbff',
            'data/full/annotations/{genome}/{genome}.embl', 'data/full/annotations/{genome}/{genome}.fna', 'data/full/annotations/{genome}/{genome}.ffn',
            'data/full/annotations/{genome}/{genome}.faa', 'data/full/annotations/{genome}/{genome}.hypotheticals.tsv', 
            'data/full/annotations/{genome}/{genome}.hypotheticals.faa', 'data/full/annotations/{genome}/{genome}.json', 
            'data/full/annotations/{genome}/{genome}.txt', 'data/full/annotations/{genome}/{genome}.png', 'data/full/annotations/{genome}/{genome}.svg'
    singularity: "docker://quay.io/biocontainers/bakta:1.11.0--pyhdfd78af_0"
    log: 'workflow/logs/bakta.{genome}.log'
    shell: """
bakta --db databases/bakta/db \
      --prefix {wildcards.genome} \
      --genus Bacillus \
      --species subtilis \
      --threads {resources.threads} \
      --force \
      --keep-contig-headers \
      --output data/full/annotations/{wildcards.genome} \
      {input.fasta} \
      > {log} 2>&1
    """

rule bakta_add_protein_metadata:
    input: 
        fasta = 'data/full/annotations/{genome}/{genome}.faa',
        gff = 'data/full/annotations/{genome}/{genome}.gff3'
    output: 
        fasta = 'data/full/fasta/proteins/{genome}.fasta'
    params:
        strain_map = strain_map
    log: 'workflow/logs/bakta_metadata.{genome}.log'
    run: 
        out_records = []

        with open(input.fasta, 'r') as in_fh:
            accession = Path(input.fasta).name.replace('.faa','')
            for record in SeqIO.parse(in_fh, 'fasta'):

                seq_id = record.id

                record.id = "lcl|" + accession + '|' + seq_id
                strain = strain_map.get(accession, 'Unknown')
                record.description = "Strain: " + strain + '; ' + record.description

                out_records.append(record)
        
        with open(output.fasta, 'w') as out_fh:
            SeqIO.write(out_records, out_fh, 'fasta')

rule bakta_proteins_blast_index:
    input: PROTEIN_FASTA
    output: PROTEIN_BLAST_DB
    params:
        species = SPECIES,
        taxid = NCBI_TAXID
    singularity: "docker://quay.io/biocontainers/blast:2.16.0--h66d330f_5"
    log: 'workflow/logs/bakta_protein_blast_index.log'
    shell: 'bin/blast_index.sh -f data/full/fasta/proteins \
                               -d data/full/blast_db \
                               -s "{params.species}" \
                               -i {params.taxid} \
                               -t p'

rule busco_lineage:
    output: BUSCO_DATA
    params: 
        lineage = busco_lineage
    singularity: "docker://quay.io/biocontainers/busco:5.8.3--pyhdfd78af_1"
    log: 'workflow/logs/busco_download.log'
    shell: 'busco --download_path databases/busco --download {params.lineage} > {log} 2>&1'

rule skani:
    input: GENOME_FILES
    output: "results/skani/skani.out"
    singularity: "docker://quay.io/biocontainers/skani:0.2.2--ha6fb395_2"
    conda: "envs/skani.yaml"
    log: 'workflow/logs/skani.log'
    shell: """
skani triangle -t {resources.threads} \
    --slow \
    -s 50 \
    -o results/skani/skani.out \
    --detailed \
    --full-matrix \
    --diagonal \
    data/full/fasta/genomes/* \
    > {log} 2>&1
"""

rule busco:
    input: 
        fasta = 'data/full/annotations/{genome}/{genome}.fna', 
        db = BUSCO_DATA
    output: 'data/full/busco/{genome}/run_bacillales_odb10/full_table.tsv'
    singularity: "docker://quay.io/biocontainers/busco:5.8.3--pyhdfd78af_1"
    params:
        lineage = busco_lineage,
        cwd = cwd
    log: 'workflow/logs/busco.{genome}.log'
    shell: """
busco -f -l {params.lineage} \
      --mode genome \
      -i {input.fasta} \
      -c {resources.threads} \
      -o data/full/busco/{wildcards.genome} \
      --offline \
      --download_path databases/busco \
      -q \
      > {log} 2>&1
    """

rule gtdb:
    output: GTDB
    params:
        gtdb_version = gtdb_version
    singularity: "docker://quay.io/biocontainers/gtdbtk:2.4.1--pyhdfd78af_0"
    log: 'workflow/logs/gtdb.log'
    shell: """
bin/download_gtdbtk_db.py \
  --release {params.gtdb_version} \
  > {log} 2>&1
"""

rule gtdbtk:
    input:
        genomes = GENOME_FILES,
        database = GTDB
    output:
        "results/gtdbtk/gtdbtk.bac120.summary.tsv"
    singularity: "docker://quay.io/biocontainers/gtdbtk:2.4.1--pyhdfd78af_0"
    log: 'workflow/logs/gtdbtk.log'
    shell: """
export GTDBTK_DATA_PATH="databases/gtdbtk"
gtdbtk classify_wf \
        --skip_ani_screen \
        --genome_dir data/full/fasta/genomes \
        --out_dir results/gtdbtk/ \
        -x fasta \
        --cpus {resources.threads} \
        --pplacer_cpus {resources.threads} \
        --tmpdir $TMPDIR \
        --force \
        > {log} 2>&1
"""

rule skani_plot: 
    input: SKANI, GTDBTK
    output: "results/skani/skani.pdf"
    singularity: "docker://quay.io/biocontainers/r-base:4.4.1"
    log: "workflow/logs/skani_plot.log"
    shell:"""
bin/ANI.R -f data/full/fasta/genomes \
          -g results/gtdbtk \
          -s results/skani/skani.out \
          -o results/skani \
          > {log} 2>&1
"""

# combine_metadata adds key GTDBTK/BUSCO to ENA download metadata, and 
# adds 'Keep' column to indicate if a genome should be taken forwards
# and an 'Exclusion criteria' column indicating which metric(s) have led
# to it being selected for exclusion

rule combine_metadata:
    input: GTDBTK
    params:
        metadata = METADATA_FILE
    output: CLASSIFIED_METADATA
    log: "workflow/logs/metadata_add_classification.log"
    run:
        combine_metadata(params.metadata, input[0], busco_lineage, busco_threshold, output[0])

rule extract_com_sequences:
    input: 
        bakta = BAKTA_ANNOTS,
        metadata = CLASSIFIED_METADATA
    output: 
        proteins = COM_PROTEINS,
        spreadsheet = 'data/full/gene_status.xlsx'
    log: "workflow/logs/extract_com_sequences.log"
    shell: """
bin/extract_com_sequences.py -d data/full -m {input.metadata} > {log} 2>&1
"""

