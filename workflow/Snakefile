from pathlib import Path
import pandas as pd
from Bio import SeqIO
from json import load

from common import (
    get_taxa_name,
    combine_metadata
)

busco_lineage = 'bacillales_odb10'
gtdb_version = '226'

cwd = Path('.').resolve()

NCBI_TAXID = "1423"
SPECIES = "Bacillus subtilis" 

GENOME_FILES = Path('data/full/fasta/genomes').glob('*')
GENOMES = [genome.stem for genome in GENOME_FILES]
METADATA_FILE = list(Path('data/full/').glob('Bacillus_subtilis_complete_genomes*'))[0]

BAKTA_DB_FILES = [ 'antifam.h3f', 'antifam.h3i', 'antifam.h3m', 'antifam.h3p', 'bakta.db',
        'expert-protein-sequences.dmnd', 'ncRNA-genes.i1f', 'ncRNA-genes.i1i', 'ncRNA-genes.i1m',
        'ncRNA-genes.i1p', 'ncRNA-regions.i1f', 'ncRNA-regions.i1i', 'ncRNA-regions.i1m',
        'ncRNA-regions.i1p', 'oric.fna', 'orit.fna', 'pfam.h3f', 'pfam.h3i', 'pfam.h3m', 'pfam.h3p',
        'rfam-go.tsv', 'rRNA.i1f', 'rRNA.i1i', 'rRNA.i1m', 'rRNA.i1p', 'sorf.dmnd'
    ]
BAKTA_DB = expand('databases/bakta/db/{file}', file = BAKTA_DB_FILES)
BAKTA_SUFFIXES = ['tsv', 'gff3', 'gbff', 'embl', 'fna', 'ffn', 'faa', 
    'hypotheticals.tsv', 'hypotheticals.faa', 'json', 'txt', 'png', 'svg']
BAKTA_ANNOTS = expand('data/full/annotations/{genome}/{genome}.{suffix}', genome = GENOMES, suffix = BAKTA_SUFFIXES)

PROTEIN_FASTA = expand('data/full/fasta/proteins/{genome}.fasta', genome = GENOMES)
PROTEIN_BLAST_SUFFIXES = ['pdb','phr','pin','pjs','pot','psq','ptf','pto']
PROTEIN_BLAST_DB = expand('data/full/blast_db/proteins/{genome}.{suffix}', genome = GENOMES, suffix = PROTEIN_BLAST_SUFFIXES)

BUSCO_DATA = expand('databases/busco/lineages/{busco_lineage}/dataset.cfg', busco_lineage = busco_lineage)
BUSCOS = expand('data/full/busco/{genome}/run_{lineage}/full_table.tsv', genome = GENOMES, lineage = busco_lineage)

SKANI = ["results/skani/skani.out"]
SKANI_PLOT = ["results/skani/skani.pdf", "results/gtdbtk/classifications.txt"]

# Way too many files in GTDB to list them all, so just one as a target
GTDB = ['databases/gtdbtk/taxonomy/gtdb_taxonomy.tsv']
GTDBTK = ['results/gtdbtk/gtdbtk.bac120.summary.tsv']

CLASSIFIED_METADATA = ["data/full/Bacillus_subtilis_classified_metadata.txt"]

with open('data/full/id_mapping.json') as fh:
    json_map = load(fh)

strain_map = {}
for k,v in json_map.items():
    if v['strain'] is not None:
        strain_map[v['accession']] = v['strain']

rule all:
    input: PROTEIN_BLAST_DB + BUSCOS + SKANI_PLOT + CLASSIFIED_METADATA

rule bakta_db:
    output: BAKTA_DB
    conda: "envs/bakta.yaml"
    log: 'workflow/logs/bakta_db.log'
    shell: 'bakta_db download --type full -o databases/bakta > {log} 2>&1'

rule bakta:
    input: 
        fasta = 'data/full/fasta/genomes/{genome}.fasta', 
        db = BAKTA_DB
    output: 'data/full/annotations/{genome}/{genome}.tsv', 'data/full/annotations/{genome}/{genome}.gff3', 'data/full/annotations/{genome}/{genome}.gbff',
            'data/full/annotations/{genome}/{genome}.embl', 'data/full/annotations/{genome}/{genome}.fna', 'data/full/annotations/{genome}/{genome}.ffn',
            'data/full/annotations/{genome}/{genome}.faa', 'data/full/annotations/{genome}/{genome}.hypotheticals.tsv', 
            'data/full/annotations/{genome}/{genome}.hypotheticals.faa', 'data/full/annotations/{genome}/{genome}.json', 
            'data/full/annotations/{genome}/{genome}.txt', 'data/full/annotations/{genome}/{genome}.png', 'data/full/annotations/{genome}/{genome}.svg'
    conda: "envs/bakta.yaml"
    log: 'workflow/logs/bakta.{genome}.log'
    shell: """
bakta --db databases/bakta/db \
      --prefix {wildcards.genome} \
      --genus Bacillus \
      --species subtilis \
      --threads {resources.threads} \
      --force \
      --keep-contig-headers \
      --output data/full/annotations/{wildcards.genome} \
      {input.fasta} \
      > {log} 2>&1
    """

rule bakta_add_protein_metadata:
    input: 
        fasta = 'data/full/annotations/{genome}/{genome}.faa',
        gff = 'data/full/annotations/{genome}/{genome}.gff3'
    output: 
        fasta = 'data/full/fasta/proteins/{genome}.fasta'
    params:
        strain_map = strain_map
    log: 'workflow/logs/bakta_metadata.{genome}.log'
    run: 
        out_records = []

        with open(input.fasta, 'r') as in_fh:
            accession = Path(input.fasta).name.replace('.faa','')
            for record in SeqIO.parse(in_fh, 'fasta'):

                seq_id = record.id

                record.id = "lcl|" + accession + '|' + seq_id
                strain = strain_map.get(accession, 'Unknown')
                record.description = "Strain: " + strain + '; ' + record.description

                out_records.append(record)
        
        with open(output.fasta, 'w') as out_fh:
            SeqIO.write(out_records, out_fh, 'fasta')

rule bakta_proteins_blast_index:
    input: PROTEIN_FASTA
    output: PROTEIN_BLAST_DB
    params:
        species = SPECIES,
        taxid = NCBI_TAXID
    conda: "envs/blast.yaml"
    log: 'workflow/logs/bakta_protein_blast_index.log'
    shell: 'bin/blast_index.sh -f data/full/fasta/proteins \
                               -d data/full/blast_db \
                               -s "{params.species}" \
                               -i {params.taxid} \
                               -t p'
    #run: 
    #    blast_index(Path('data/full/fasta/proteins'), Path('data/full/blast_db/'),
    #                SPECIES, NCBI_TAXID, 'prot')

rule busco_lineage:
    output: BUSCO_DATA
    params: 
        lineage = busco_lineage
    conda: "envs/busco.yaml"
    log: 'workflow/logs/busco_download.log'
    shell: 'busco --download_path databases/busco --download {params.lineage} > {log} 2>&1'

rule skani:
    input: GENOME_FILES
    output: "results/skani/skani.out"
    conda: "envs/skani.yaml"
    log: 'workflow/logs/skani.log'
    shell: """
skani triangle -t {resources.threads} \
    --slow \
    -s 50 \
    -o results/skani/skani.out \
    --detailed \
    --full-matrix \
    --diagonal \
    data/full/fasta/genomes/* \
    > {log} 2>&1
"""

rule busco:
    input: 
        fasta = 'data/full/annotations/{genome}/{genome}.fna', 
        db = BUSCO_DATA
    output: 'data/full/busco/{genome}/run_bacillales_odb10/full_table.tsv'
    conda: "envs/busco.yaml"
    params:
        lineage = busco_lineage,
        cwd = cwd
    log: 'workflow/logs/busco.{genome}.log'
    shell: """
busco -f -l {params.lineage} \
      --mode genome \
      -i {input.fasta} \
      -c {resources.threads} \
      -o data/full/busco/{wildcards.genome} \
      --offline \
      --download_path databases/busco \
      -q \
      > {log} 2>&1
    """

rule gtdb:
    output: GTDB
    params:
        gtdb_version = gtdb_version
    conda: "envs/gtdbtk.yaml"
    log: 'workflow/logs/gtdb.log'
    shell: """
bin/download_gtdbtk_db.py \
  --release {params.gtdb_version} \
  > {log} 2>&1
"""

rule gtdbtk:
    input:
        genomes = GENOME_FILES,
        database = GTDB
    output:
        "results/gtdbtk/gtdbtk.bac120.summary.tsv"
    conda: "envs/gtdbtk.yaml"
    log: 'workflow/logs/gtdbtk.log'
    shell: """
export GTDBTK_DATA_PATH="databases/gtdbtk"
gtdbtk classify_wf \
        --skip_ani_screen \
        --genome_dir data/full/fasta/genomes \
        --out_dir results/gtdbtk/ \
        -x fasta \
        --cpus {resources.threads} \
        --pplacer_cpus {resources.threads} \
        --tmpdir $TMPDIR \
        --force \
        > {log} 2>&1
"""

rule skani_plot: 
    input: SKANI, GTDBTK
    output: "results/skani/skani.pdf", "results/gtdbtk/classifications.txt"
    conda: "envs/R.yaml"
    log: "workflow/logs/skani_plot.log"
    shell:"""
bin/ANI.R -f data/full/fasta/genomes \
          -g results/gtdbtk \
          -s results/skani/skani.out \
          -o results/skani \
          > {log} 2>&1
"""

# metadata_add_classification takes the gtdbtk outputs and adds the gtdb taxonomic
# classification to the metadata file generated by 00_build_genome_dbs.py including
# a 'Keep' column indicating a genome should be retained for downstream analysis.

# This can be manually modified as required, but will by default retain all B. subtilis genomes

rule metadata_add_classification:
    input: GTDBTK
    params:
        metadata = METADATA_FILE
    output: CLASSIFIED_METADATA
    log: "workflow/logs/metadata_add_classification.log"
    run:
        combine_metadata(params.metadata, input[0], output[0])
#        metadata = pd.read_csv(params.metadata, sep="\t")
#        classifications = pd.read_csv(input[0], sep="\t")
#
#        # Add species column, and 'keep' column, set to 1 where species is subtilis
#        classifications['Species'] = classifications['classification'].map(lambda x: x.split(';')[-1].replace('s__',''))
#        classifications['Keep'] = 0
#        classifications.loc[classifications['Species' ]== "Bacillus subtilis", 'Keep'] = 1
#        classifications = classifications[['user_genome','Species', 'Keep']]
#        metadata = pd.merge(metadata, classifications, how='inner', left_on='Accession', right_on='user_genome')
##        metadata = metadata.drop('user_genome', axis = 1)
#        metadata.to_csv(output[0], sep="\t", index=False)
