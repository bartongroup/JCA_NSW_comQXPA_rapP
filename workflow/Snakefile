from pathlib import Path
import pandas as pd
from Bio import SeqIO
from json import load

from common import (
    blast_index,
    get_taxa_name
)

busco_lineage = 'bacillales_odb10'
gtdb_version = '220'

cwd = Path('.').resolve()

NCBI_TAXID = "1423"
SPECIES = get_taxa_name(NCBI_TAXID)

GENOME_FILES = Path('data/full/fasta/genomes').glob('*')
GENOMES = [genome.stem for genome in GENOME_FILES]
BAKTA_DB_FILES = [ 'antifam.h3f', 'antifam.h3i', 'antifam.h3m', 'antifam.h3p', 'bakta.db',
        'expert-protein-sequences.dmnd', 'ncRNA-genes.i1f', 'ncRNA-genes.i1i', 'ncRNA-genes.i1m',
        'ncRNA-genes.i1p', 'ncRNA-regions.i1f', 'ncRNA-regions.i1i', 'ncRNA-regions.i1m',
        'ncRNA-regions.i1p', 'oric.fna', 'orit.fna', 'pfam.h3f', 'pfam.h3i', 'pfam.h3m', 'pfam.h3p',
        'rfam-go.tsv', 'rRNA.i1f', 'rRNA.i1i', 'rRNA.i1m', 'rRNA.i1p', 'sorf.dmnd'
    ]
BAKTA_DB = expand('databases/bakta/db/{file}', file = BAKTA_DB_FILES)
BAKTA_SUFFIXES = ['tsv', 'gff3', 'gbff', 'embl', 'fna', 'ffn', 'faa', 
    'hypotheticals.tsv', 'hypotheticals.faa', 'json', 'txt', 'png', 'svg']
BAKTA_ANNOTS = expand('data/full/annotations/{genome}/{genome}.{suffix}', genome = GENOMES, suffix = BAKTA_SUFFIXES)
PROTEIN_FASTA = expand('data/full/fasta/proteins/{genome}.fasta', genome = GENOMES)
PROTEIN_BLAST_SUFFIXES = ['pdb','phr','pin','pjs','pot','psq','ptf','pto']
PROTEIN_BLAST_DB = expand('data/full/blast_db/proteins/{genome}.{suffix}', genome = GENOMES, suffix = PROTEIN_BLAST_SUFFIXES)
BUSCO_DATA = expand('databases/busco/lineages/{busco_lineage}/dataset.cfg', busco_lineage = busco_lineage)
BUSCOS = expand('data/full/busco/{genome}/run_{lineage}/full_table.tsv', genome = GENOMES, lineage = busco_lineage)
SKANI = ["results/skani/skani.out"]
SKANI_PLOT = ["results/skani/skani.pdf", "results/gtdbtk/classifications.txt"]

# Way too many files in GTDB to list them all, so just one as a target
GTDB = ['databases/gtdbtk/taxonomy/gtdb_taxonomy.tsv']
GTDBTK = ['results/gtdbtk/gtdbtk.bac120.summary.tsv']


with open('data/full/id_mapping.json') as fh:
    json_map = load(fh)

strain_map = {}
for k,v in json_map.items():
    strain_map[v['accession']] = v['strain']

rule all:
    input: PROTEIN_BLAST_DB + BUSCOS + SKANI_PLOT + GTDBTK

rule bakta_db:
    output: BAKTA_DB
    conda: 'envs/bakta.yaml'
    log: 'workflow/logs/bakta_db.log'
    shell: 'bakta_db download --type full -o databases/bakta > {log} 2>&1'

rule bakta:
    input: 
        fasta = 'data/full/fasta/genomes/{genome}.fasta', 
        db = BAKTA_DB
    output: 'data/full/annotations/{genome}/{genome}.tsv', 'data/full/annotations/{genome}/{genome}.gff3', 'data/full/annotations/{genome}/{genome}.gbff',
            'data/full/annotations/{genome}/{genome}.embl', 'data/full/annotations/{genome}/{genome}.fna', 'data/full/annotations/{genome}/{genome}.ffn',
            'data/full/annotations/{genome}/{genome}.faa', 'data/full/annotations/{genome}/{genome}.hypotheticals.tsv', 
            'data/full/annotations/{genome}/{genome}.hypotheticals.faa', 'data/full/annotations/{genome}/{genome}.json', 
            'data/full/annotations/{genome}/{genome}.txt', 'data/full/annotations/{genome}/{genome}.png', 'data/full/annotations/{genome}/{genome}.svg'
    conda: 'envs/bakta.yaml'
    log: 'workflow/logs/bakta.{genome}.log'
    shell: """
bakta --db databases/bakta/db \
      --prefix {wildcards.genome} \
      --genus Bacillus \
      --species subtilis \
      --threads 2 \
      --force \
      --keep-contig-headers \
      --output data/full/annotations/{wildcards.genome} \
      {input.fasta} \
      > {log} 2>&1
    """

rule bakta_add_protein_metadata:
    input: 
        fasta = 'data/full/annotations/{genome}/{genome}.faa',
        gff = 'data/full/annotations/{genome}/{genome}.gff3'
    output: 
        fasta = 'data/full/fasta/proteins/{genome}.fasta'
    params:
        strain_map = strain_map
    log: 'workflow/logs/bakta_metadata.{genome}.log'
    run: 
        out_records = []

        with open(input.fasta, 'r') as in_fh:
            accession = Path(input.fasta).name.replace('.faa','')
            for record in SeqIO.parse(in_fh, 'fasta'):

                seq_id = record.id

                record.id = "lcl|" + accession + '|' + seq_id
                strain = strain_map[accession] or 'Unknown'
                record.description = "Strain: " + strain + '; ' + record.description

                out_records.append(record)
        
        with open(output.fasta, 'w') as out_fh:
            SeqIO.write(out_records, out_fh, 'fasta')

rule bakta_proteins_blast_index:
    input: PROTEIN_FASTA
    output: PROTEIN_BLAST_DB
    log: 'workflow/logs/bakta_protein_blat_index.log'
    run: 
        blast_index(Path('data/full/fasta/proteins'), Path('data/full/blast_db/'),
                    SPECIES, NCBI_TAXID, 'prot')

rule busco_lineage:
    output: BUSCO_DATA
    params: 
        lineage = busco_lineage
    conda: 'envs/busco.yaml'
    log: 'workflow/logs/busco_download.log'
    shell: 'busco --download_path databases/busco --download {params.lineage} > {log} 2>&1'

rule skani:
    input: GENOME_FILES
    output: "results/skani/skani.out"
    conda: 'envs/skani.yaml'
    log: 'workflow/logs/skani.log'
    shell: """
skani triangle -t 24 \
    --slow \
    -s 50 \
    -o results/skani/skani.out \
    --detailed \
    --full-matrix \
    --diagonal \
    data/full/fasta/genomes/* \
    > {log} 2>&1
"""

rule busco:
    input: 
        fasta = 'data/full/annotations/{genome}/{genome}.fna', 
        db = BUSCO_DATA
    output: 'data/full/busco/{genome}/run_bacillales_odb10/full_table.tsv'
    conda: 'envs/busco.yaml'
    params:
        lineage = busco_lineage,
        cwd = cwd
    log: 'workflow/logs/busco.{genome}.log'
    shell: """
busco -f -l {params.lineage} \
      --mode genome \
      -i {input.fasta} \
      -c 8 \
      -o data/full/busco/{wildcards.genome} \
      --offline \
      --download_path databases/busco \
      -q \
      > {log} 2>&1
    """


rule gtdb:
    output: GTDB
    params:
        gtdb_version = gtdb_version
    conda: "envs/gtdbtk.yaml"
    log: 'workflow/logs/gtdb.log'
    shell: """
bin/download_gtdbtk_db.py \
  --release {params.gtdb_version} \
  > {log} 2>&1
"""

rule gtdbtk:
    input:
        genomes = GENOME_FILES,
        database = GTDB
    output:
        "results/gtdbtk/gtdbtk.bac120.summary.tsv"
    conda: "envs/gtdbtk.yaml"
    log: 'workflow/logs/gtdbtk.log'
    shell: """
export GTDBTK_DATA_PATH="databases/gtdbtk"
gtdbtk classify_wf \
        --skip_ani_screen \
        --genome_dir data/full/fasta \
        --out_dir results/gtdbtk/ \
        -x fasta \
        --cpus 32 \
        --pplacer_cpus 32 \
        --tmpdir $TMPDIR \
        --force \
        > {log} 2>&1
"""

rule skani_plot: 
    input: SKANI, GTDBTK
    output: "results/skani/skani.pdf", "results/gtdbtk/classifications.txt"
    conda: "envs/R.yaml"
    log: "workflow/logs/skani_plot.log"
    shell:"""
bin/ANI.R -f data/full/fasta/genomes \
          -g results/gtdbtk \
          -s results/skani/skani.out \
          -o results/skani \
          > {log} 2>&1
"""